{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61291dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GITHUB_API_KEY = os.getenv(\"GITHUB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "513f2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from google.genai import types\n",
    "\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.runners import InMemoryRunner, Runner\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "\n",
    "from google.adk.tools.mcp_tool.mcp_toolset import McpToolset\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams, StreamableHTTPConnectionParams\n",
    "from mcp import StdioServerParameters\n",
    "\n",
    "from google.adk.apps.app import App, ResumabilityConfig\n",
    "from google.adk.tools.function_tool import FunctionTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d89f85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf081ab",
   "metadata": {},
   "source": [
    "### 2.1: How MCP Works\n",
    "\n",
    "MCP connects your agent (the **client**) to external **MCP servers** that provide tools:\n",
    "\n",
    "- **MCP Server**: Provides specific tools (like image generation, database access)\n",
    "- **MCP Client**: Your agent that uses those tools\n",
    "- **All servers work the same way** - standardized interface\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "┌──────────────────┐\n",
    "│   Your Agent     │\n",
    "│   (MCP Client)   │\n",
    "└────────┬─────────┘\n",
    "         │\n",
    "         │ Standard MCP Protocol\n",
    "         │\n",
    "    ┌────┴────┬────────┬────────┐\n",
    "    │         │        │        │\n",
    "    ▼         ▼        ▼        ▼\n",
    "┌────────┐ ┌─────┐ ┌──────┐ ┌─────┐\n",
    "│ GitHub │ │Slack│ │ Maps │ │ ... │\n",
    "│ Server │ │ MCP │ │ MCP  │ │     │\n",
    "└────────┘ └─────┘ └──────┘ └─────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2898767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_server_image = McpToolset(\n",
    "    connection_params=StdioConnectionParams(\n",
    "        server_params=StdioServerParameters(\n",
    "            command=\"npx\",\n",
    "            args=['-y',\"@modelcontextprotocol/server-everything\"],\n",
    "            tool_filter = [\"getTinyImage\"]\n",
    "        ),\n",
    "        timeout=30\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb7aedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image agent with MCP integration\n",
    "image_agent = LlmAgent(\n",
    "    name = \"image_agent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"Use the MCP Tool to generate images for user queries\",\n",
    "    tools=[mcp_server_image]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b1b0e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Provide a sample tiny image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/poojan/programs/personal-programs/5dgai/.venv/lib/python3.11/site-packages/google/adk/tools/mcp_tool/mcp_tool.py:101: UserWarning: [EXPERIMENTAL] BaseAuthenticatedTool: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  super().__init__(\n",
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_agent > [Calling tool: getTinyImage({})]\n",
      "image_agent > [Tool result: {'content': [{'type': 'text', 'text': 'This is a tiny image:'}, {'type': 'image', 'data': 'iVBORw0KG...]\n",
      "image_agent > This is a tiny image:\n",
      "The image above is the MCP tiny image.\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(agent = image_agent)\n",
    "response = await runner.run_debug(\"Provide a sample tiny image\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3792062f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image as IPImage\n",
    "import base64\n",
    "\n",
    "for event in response:\n",
    "    if event.content and event.content.parts:\n",
    "        for part in event.content.parts:\n",
    "            if hasattr(part, \"function_response\") and part.function_response:\n",
    "                for item in part.function_response.response.get(\"content\", []):\n",
    "                    if item.get(\"type\") == \"image\":\n",
    "                        display(IPImage(data=base64.b64decode(item[\"data\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b498a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_mcp_server = McpToolset(\n",
    "    connection_params=StdioConnectionParams(\n",
    "        server_params=StdioServerParameters(\n",
    "            command='npx',\n",
    "            args=[\n",
    "                '-y',\n",
    "                'mcp-remote',\n",
    "                'https://www.kaggle.com/mcp'\n",
    "            ],\n",
    "        ),\n",
    "        timeout=1000\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df8b8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_agent = LlmAgent(\n",
    "    name = \"kaggle_agent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"Use the MCP Tool to search, download and perform multiple actions for database in kaggle\",\n",
    "    tools=[kaggle_mcp_server]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef174521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > I need large dataset for weapon detection in multiple scenerious\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/poojan/programs/personal-programs/5dgai/.venv/lib/python3.11/site-packages/google/adk/tools/mcp_tool/mcp_tool.py:101: UserWarning: [EXPERIMENTAL] BaseAuthenticatedTool: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  super().__init__(\n",
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle_agent > [Calling tool: search_datasets({'request': {'search': 'weapon detection', 'size':...)]\n",
      "kaggle_agent > [Tool result: {'content': [{'type': 'text', 'text': '{\\n  \"datasets\": [\\n    {\\n      \"id\": 4895326,\\n      \"ref\":...]\n"
     ]
    }
   ],
   "source": [
    "kaggle_runner = InMemoryRunner(agent=kaggle_agent)\n",
    "response= await kaggle_runner.run_debug(\"I need large dataset for weapon detection in multiple scenerious\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f16b22e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Event(model_version='gemini-2.5-flash-lite', content=Content(\n",
       "   parts=[\n",
       "     Part(\n",
       "       function_call=FunctionCall(\n",
       "         args={\n",
       "           'request': {\n",
       "             'search': 'weapon detection',\n",
       "             'size': 'Large'\n",
       "           }\n",
       "         },\n",
       "         id='adk-b75baf9b-cda9-442b-be28-823ad4aa3f39',\n",
       "         name='search_datasets'\n",
       "       )\n",
       "     ),\n",
       "   ],\n",
       "   role='model'\n",
       " ), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "   cache_tokens_details=[\n",
       "     ModalityTokenCount(\n",
       "       modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "       token_count=13960\n",
       "     ),\n",
       "   ],\n",
       "   cached_content_token_count=13960,\n",
       "   candidates_token_count=26,\n",
       "   prompt_token_count=14005,\n",
       "   prompt_tokens_details=[\n",
       "     ModalityTokenCount(\n",
       "       modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "       token_count=14005\n",
       "     ),\n",
       "   ],\n",
       "   total_token_count=14031\n",
       " ), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-2613d43d-320e-4d28-b464-b5aed3ad902b', author='kaggle_agent', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=set(), branch=None, id='3dbc35c8-f662-462f-a200-41b68f05355c', timestamp=1763560949.313407),\n",
       " Event(model_version=None, content=Content(\n",
       "   parts=[\n",
       "     Part(\n",
       "       function_response=FunctionResponse(\n",
       "         id='adk-b75baf9b-cda9-442b-be28-823ad4aa3f39',\n",
       "         name='search_datasets',\n",
       "         response={\n",
       "           'content': [\n",
       "             {<... 2 items at Max depth ...>},\n",
       "           ],\n",
       "           'isError': False\n",
       "         }\n",
       "       )\n",
       "     ),\n",
       "   ],\n",
       "   role='user'\n",
       " ), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=None, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=None, live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-2613d43d-320e-4d28-b464-b5aed3ad902b', author='kaggle_agent', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='66c62cc1-cf2d-40fa-aaa1-59a5122f5b3b', timestamp=1763560951.534424),\n",
       " Event(model_version='gemini-2.5-flash-lite', content=Content(\n",
       "   role='model'\n",
       " ), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "   cache_tokens_details=[\n",
       "     ModalityTokenCount(\n",
       "       modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "       token_count=16098\n",
       "     ),\n",
       "   ],\n",
       "   cached_content_token_count=16098,\n",
       "   prompt_token_count=21909,\n",
       "   prompt_tokens_details=[\n",
       "     ModalityTokenCount(\n",
       "       modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "       token_count=21909\n",
       "     ),\n",
       "   ],\n",
       "   total_token_count=21909\n",
       " ), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-2613d43d-320e-4d28-b464-b5aed3ad902b', author='kaggle_agent', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='2b00a0ec-3b01-4768-a370-c867d65cb0c0', timestamp=1763560952.104124)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea3335b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_mcp_server = McpToolset(\n",
    "    connection_params=StreamableHTTPConnectionParams(\n",
    "        url=\"https://api.githubcopilot.com/mcp/\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {GITHUB_API_KEY}\",\n",
    "            \"X-MCP-Toolsets\": \"all\",\n",
    "            \"X-MCP-Readonly\": \"true\"\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d045139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_agent = LlmAgent(\n",
    "    name = \"github_agent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"Use the MCP Tool to perform varioud github actions\",\n",
    "    tools=[github_mcp_server]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deaead1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > List files in https://github.com/poojan-solanki/bounding-boxes-by-gemini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "github_agent > The repository contains the following files:\n",
      "- README.md\n",
      "- bounding_boxes.py\n",
      "- label_images.py\n",
      "- test_code.py\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(agent=github_agent)\n",
    "response = await runner.run_debug(\"List files in https://github.com/poojan-solanki/bounding-boxes-by-gemini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9f34f4",
   "metadata": {},
   "source": [
    "#### Long-Running Operations (Human-in-the-Loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d204c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE_ORDER_THRESHHOLD = 5\n",
    "\n",
    "def place_shipping_order(num_containers: int, destination: str, tool_context: ToolContext):\n",
    "    \"\"\"Places a shipping order. Requires approval if ordering more than 5 containers (LARGE_ORDER_THRESHOLD).\n",
    "\n",
    "    Args:\n",
    "        num_containers: Number of containers to ship\n",
    "        destination: Shipping destination\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with order status\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # SCENARIO 1: Small orders (≤5 containers) auto-approve\n",
    "    if num_containers <= LARGE_ORDER_THRESHHOLD:\n",
    "        return {\n",
    "            \"status\": \"approved\",\n",
    "            \"order_id\": f\"ORD-{num_containers}-AUTO\",\n",
    "            \"num_containers\":num_containers,\n",
    "            \"destination\": destination,\n",
    "            \"message\": f\"Order auto-appproved: {num_containers} containers at {destination}\"\n",
    "        }\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # SCENARIO 2: This is the first time this tool is called. Large orders need human approval - PAUSE here.\n",
    "    if not tool_context.tool_confirmation:\n",
    "        tool_context.request_confirmation(\n",
    "            hint=f\"⚠️ Large order: {num_containers} containers to {destination}. Do you want to approve?\",\n",
    "            payload={\"num_ocntainers\": num_containers, \"destination\": destination}\n",
    "        )\n",
    "        return {  # This is sent to agent\n",
    "            \"status\" : \"pending\",\n",
    "            \"message\": f\"Order for {num_containers} containers requires approval\",\n",
    "        }\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # SCENARIO 3: The tool is called AGAIN and is now resuming. Handle approval response - RESUME here.\n",
    "    if tool_context.tool_confirmation.confirmed:\n",
    "        return {\n",
    "            \"status\": \"approved\",\n",
    "            \"order_id\": f\"ORD-{num_containers}-HUMAN\",\n",
    "            \"num_containers\": num_containers,\n",
    "            \"destination\": destination,\n",
    "            \"message\": f\"Order approved: {num_containers} containers to {destination}\",\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"status\": \"rejected\",\n",
    "            \"message\": f\"Order rejected: {num_containers} containers to {destination}\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4cfe46",
   "metadata": {},
   "source": [
    "### Understanding the Code\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day2/lro-tool.png\" width=\"1000\" alt=\"Long-running operation tool\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a18a1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "shipping_agent = LlmAgent(\n",
    "    name=\"shipping_agent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are a shipping coordinator assistant.\n",
    "  \n",
    "  When users request to ship containers:\n",
    "   1. Use the place_shipping_order tool with the number of containers and destination\n",
    "   2. If the order status is 'pending', inform the user that approval is required\n",
    "   3. After receiving the final result, provide a clear summary including:\n",
    "      - Order status (approved/rejected)\n",
    "      - Order ID (if available)\n",
    "      - Number of containers and destination\n",
    "   4. Keep responses concise but informative\n",
    "  \"\"\",\n",
    "    tools=[FunctionTool(func=place_shipping_order)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "215a0cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133512/133059918.py:6: UserWarning: [EXPERIMENTAL] ResumabilityConfig: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  resumability_config=ResumabilityConfig(is_resumable=True)\n"
     ]
    }
   ],
   "source": [
    "# Wrap the agent in a resuable app - THIS IS THE KEY FOR LONG RUNNING APPS!\n",
    "\n",
    "shipping_app = App(\n",
    "    name= \"shipping_coordinator\",\n",
    "    root_agent=shipping_agent,\n",
    "    resumability_config=ResumabilityConfig(is_resumable=True)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5ab4774",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_service = InMemorySessionService()\n",
    "shipping_runner = Runner(\n",
    "    app=shipping_app,\n",
    "    session_service=session_service\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d57adc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5dgai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
